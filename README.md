# Toast POS to BigQuery Data Warehouse

**Enterprise-grade ETL pipeline for Toast Restaurant POS data with Power BI analytics**

## Quick Start

```bash
# 1. Deploy improved Cloud Function
./deploy.sh

# 2. Load historical data (2025-2026)
./historical_load.sh

# 3. Transform to dimensional model
bq query --use_legacy_sql=false < etl_load_dimensions.sql
bq query --use_legacy_sql=false < etl_load_facts.sql

# 4. Setup daily automation
./setup_scheduler.sh

# 5. Connect Power BI to BigQuery dataset 'purpose'
```

## Project Structure

```
toast-api/
‚îú‚îÄ‚îÄ main.py                      # Current (original) Cloud Function
‚îú‚îÄ‚îÄ main_improved.py             # ‚ú® Enhanced version with date ranges
‚îú‚îÄ‚îÄ requirements.txt             # Python dependencies
‚îÇ
‚îú‚îÄ‚îÄ üìä ETL & Transformation
‚îÇ   ‚îú‚îÄ‚îÄ create_staging_table.sql      # Create toast.orders staging
‚îÇ   ‚îú‚îÄ‚îÄ transform_to_dimensions.sql   # Create dimensional tables
‚îÇ   ‚îú‚îÄ‚îÄ etl_load_dimensions.sql       # Load dimensions (SCD Type 2)
‚îÇ   ‚îú‚îÄ‚îÄ etl_load_facts.sql            # Load fact tables (MERGE)
‚îÇ   ‚îî‚îÄ‚îÄ powerbi_queries.sql           # 8 analytical views for dashboards
‚îÇ
‚îú‚îÄ‚îÄ üöÄ Deployment & Automation
‚îÇ   ‚îú‚îÄ‚îÄ deploy.sh                     # Deploy Cloud Function
‚îÇ   ‚îú‚îÄ‚îÄ historical_load.sh            # Backfill 2025-2026 data
‚îÇ   ‚îú‚îÄ‚îÄ setup_scheduler.sh            # Daily automation (Cloud Scheduler)
‚îÇ   ‚îî‚îÄ‚îÄ run_daily_etl.sh              # Master ETL orchestration
‚îÇ
‚îú‚îÄ‚îÄ üß™ Testing & Validation
‚îÇ   ‚îú‚îÄ‚îÄ test_toast_api.py             # Local API connection test
‚îÇ   ‚îú‚îÄ‚îÄ bigquery_check.sql            # Data validation queries
‚îÇ   ‚îî‚îÄ‚îÄ check_env.sh                  # Verify environment variables
‚îÇ
‚îî‚îÄ‚îÄ üìñ Documentation
    ‚îú‚îÄ‚îÄ README.md                     # This file
    ‚îú‚îÄ‚îÄ ETL_DOCUMENTATION.md          # Complete technical docs
    ‚îú‚îÄ‚îÄ DEPLOYMENT_GUIDE.md           # Step-by-step deployment
    ‚îú‚îÄ‚îÄ IMPROVEMENTS.md               # What was improved
    ‚îú‚îÄ‚îÄ AUDIT_SUMMARY.md              # Code audit results
    ‚îî‚îÄ‚îÄ MEMORY.md                     # Learnings (auto memory)
```

## Architecture

### Star Schema Design
```
Purpose Dataset (Dimensional Model)
‚îÇ
‚îú‚îÄ üìè Dimensions (SCD Type 2)
‚îÇ   ‚îú‚îÄ DimLocation        13 restaurants
‚îÇ   ‚îú‚îÄ DimEmployee        Servers & staff (with history)
‚îÇ   ‚îú‚îÄ DimJob             Job roles
‚îÇ   ‚îî‚îÄ DimMenuItem        Menu items (price history)
‚îÇ
‚îú‚îÄ üìä Facts (Partitioned by date)
‚îÇ   ‚îú‚îÄ FactOrders         1 row per order
‚îÇ   ‚îú‚îÄ FactChecks         1 row per guest check
‚îÇ   ‚îú‚îÄ FactPayments       1 row per payment
‚îÇ   ‚îú‚îÄ FactMenuSelection  1 row per item ordered
‚îÇ   ‚îú‚îÄ FactCashEntries    Cash drawer transactions
‚îÇ   ‚îú‚îÄ FactDeposits       Bank deposits
‚îÇ   ‚îî‚îÄ FactTimeEntries    Employee time clock
‚îÇ
‚îî‚îÄ üìà Analytical Views (Power BI-ready)
    ‚îú‚îÄ vw_DailySalesByLocation
    ‚îú‚îÄ vw_ServerPerformance
    ‚îú‚îÄ vw_MenuItemPerformance
    ‚îú‚îÄ vw_PaymentTypeAnalysis
    ‚îú‚îÄ vw_HourlySalesTrend
    ‚îú‚îÄ vw_LaborProductivity
    ‚îú‚îÄ vw_PeriodComparison
    ‚îî‚îÄ vw_TopServersByShift
```

## What This Gives You

### üéØ Business Analytics
- **Revenue Analysis:** Daily sales by location, daypart, server
- **Menu Performance:** Best-sellers, revenue contribution, pricing analysis
- **Labor Optimization:** Sales per hour, labor cost %, productivity rankings
- **Server Performance:** Sales rankings, tip %, table turn time
- **Trend Analysis:** Day-over-day, week-over-week, rolling averages

### üèóÔ∏è Technical Features
- ‚úÖ **Incremental Loads:** Only process new data
- ‚úÖ **Deduplication:** MERGE prevents duplicate records
- ‚úÖ **History Tracking:** SCD Type 2 for employee/menu changes
- ‚úÖ **Partitioned Tables:** Optimized for date-range queries
- ‚úÖ **Clustered Keys:** Fast joins and aggregations
- ‚úÖ **Metadata Tracking:** Data lineage, load timestamps
- ‚úÖ **Error Handling:** Continue processing on partial failures

## Current vs Improved

| Feature | Original | Improved |
|---------|----------|----------|
| Date Range | Yesterday only | Any date range |
| Error Handling | Stop on first error | Continue all restaurants |
| Test Mode | None | `?mode=test` |
| Response Format | Plain text | JSON |
| Metadata | None | Load timestamp, source tracking |
| Dataset Name | Hardcoded 'purpose' | Correct 'purpose' |
| Deduplication | None | MERGE statements |
| Historical Load | Not possible | ‚úÖ Full backfill |

## Environment Variables

Set in Cloud Function:
```bash
TOAST_CLIENT_ID=your-client-id
TOAST_CLIENT_SECRET=your-secret
BQ_PROJECT_ID=possible-coast-439421-q5
BQ_DATASET_ID=purpose
RESTAURANT_GUIDS=6d035dad-924f-47b4-ba93-fd86575e73a3,53ae28f1-87c7-4a07-9a43-b619c009b7b0,...
```

## Daily Operations

### Automated (via Cloud Scheduler)
- **2:00 AM:** Cloud Function extracts yesterday's orders
- **2:15 AM:** Load dimensions (SCD updates)
- **2:30 AM:** Load facts (incremental)
- **3:00 AM:** Power BI refreshes (if scheduled)

### Manual Triggers
```bash
# Fetch specific date range
curl -X POST https://toast-purpose-bulk-120665665070.us-west1.run.app \
  -H "Content-Type: application/json" \
  -d '{"start_date": "2025-12-01", "end_date": "2025-12-31"}'

# Test without loading data
curl "https://toast-purpose-bulk-120665665070.us-west1.run.app?mode=test"

# Run full ETL pipeline
./run_daily_etl.sh

# View logs
gcloud functions logs read toast-purpose-bulk --gen2 --region=us-west1
```

## Power BI Setup

1. **Connect to BigQuery:**
   - Project: `possible-coast-439421-q5`
   - Dataset: `purpose`
   - Mode: DirectQuery (real-time) or Import (faster)

2. **Import These Tables:**
   - All `FactXXX` tables (star schema center)
   - All `DimXXX` tables (dimensions)
   - All `vw_XXX` views (pre-aggregated)

3. **Create Relationships:**
   ```
   FactOrders[LocationKey] ‚Üí DimLocation[LocationKey]
   FactChecks[ServerKey] ‚Üí DimEmployee[EmployeeKey]
   FactMenuSelection[MenuItemKey] ‚Üí DimMenuItem[MenuItemKey]
   ```

4. **Sample Dashboard Pages:**
   - Executive Summary (revenue, trends, top locations)
   - Server Performance (rankings, tips, productivity)
   - Menu Analysis (best-sellers, pricing, categories)
   - Labor Management (hours, cost %, efficiency)
   - Payment Analysis (cash vs card, trends)

## Monitoring & Alerts

### Health Checks
```sql
-- Check latest data load
SELECT MAX(BusinessDate) as latest_date
FROM `possible-coast-439421-q5.purpose.FactOrders`;

-- Verify row counts
SELECT
  'Orders' as table_name, COUNT(*) as row_count
FROM `possible-coast-439421-q5.purpose.FactOrders`
UNION ALL
SELECT 'Checks', COUNT(*) FROM `possible-coast-439421-q5.purpose.FactChecks`;
```

### Recommended Alerts
- No data for current day by 3 AM
- Order count drops >50% day-over-day
- ETL job failures
- BigQuery cost spikes

## Costs

**Estimated Monthly:**
- Cloud Function: $5-10
- BigQuery Storage (100GB): $10-20
- BigQuery Queries: $20-50
- **Total: ~$35-80/month**

**Optimization:**
- Use partition pruning (always filter by date)
- Materialize expensive views
- Set data retention (90 days for staging)

## Troubleshooting

### No data loading?
```bash
# Check Cloud Function logs
gcloud functions logs read toast-purpose-bulk --gen2 --region=us-west1 --limit=50

# Check staging table
bq query "SELECT COUNT(*), MAX(business_date) FROM \`possible-coast-439421-q5.toast.orders\`"
```

### Duplicates in fact tables?
```sql
-- Run deduplication
CREATE OR REPLACE TABLE `possible-coast-439421-q5.purpose.FactOrders_clean` AS
SELECT * EXCEPT(row_num)
FROM (
  SELECT *, ROW_NUMBER() OVER (PARTITION BY OrderGuid ORDER BY _LoadedAt DESC) as row_num
  FROM `possible-coast-439421-q5.purpose.FactOrders`
)
WHERE row_num = 1;
```

### Performance issues?
- Ensure queries filter on partition column (`BusinessDate`)
- Use clustered columns in WHERE/JOIN
- Check query execution plan in BigQuery console

## Documentation

- **[ETL_DOCUMENTATION.md](ETL_DOCUMENTATION.md)** - Complete technical reference
- **[DEPLOYMENT_GUIDE.md](DEPLOYMENT_GUIDE.md)** - Step-by-step setup
- **[AUDIT_SUMMARY.md](AUDIT_SUMMARY.md)** - Code audit results
- **[IMPROVEMENTS.md](IMPROVEMENTS.md)** - What was fixed/enhanced

## Support

- Toast API: https://doc.toasttab.com/
- BigQuery: https://cloud.google.com/bigquery/docs
- Power BI: https://docs.microsoft.com/power-bi/

## Status

- ‚úÖ **Code Audit:** Complete - System is functional
- ‚úÖ **Improvements:** Complete - Date range support added
- ‚úÖ **ETL Design:** Complete - Star schema with SCD Type 2
- ‚úÖ **Documentation:** Complete - Full technical docs
- ‚è≥ **Deployment:** Ready to deploy
- ‚è≥ **Historical Load:** Ready to execute
- ‚è≥ **Power BI:** Ready to connect

## Next Steps

1. **Review** the improved code ([main_improved.py](main_improved.py))
2. **Deploy** the updated Cloud Function ([deploy.sh](deploy.sh))
3. **Test** with a single day ([DEPLOYMENT_GUIDE.md](DEPLOYMENT_GUIDE.md))
4. **Load** historical data ([historical_load.sh](historical_load.sh))
5. **Transform** to dimensional model (run SQL scripts)
6. **Connect** Power BI to BigQuery
7. **Automate** with Cloud Scheduler ([setup_scheduler.sh](setup_scheduler.sh))

---

**Version:** 1.0
**Last Updated:** 2026-02-09
**Status:** Production-Ready ‚úÖ
